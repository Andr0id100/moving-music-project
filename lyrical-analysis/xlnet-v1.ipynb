{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19ba5fe0-1c6c-4268-a2a9-23606a10c696",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, XLNetModel, AdamW\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ad05e39-1468-4087-8183-808a30440ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 1024\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9fcbaab-7d66-41b0-8c07-f502d01d4867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c3e766257c41de810a960423698e85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c953db94a0c64c459565ed8ec4eaae71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef9647c6-5bae-448e-b0d0-71d94a02422b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd58e99a934842d7a683470870a06b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9cd67b7-912b-4923-bb5e-6cb49a0dc234",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): XLNetForSequenceClassification(\n",
       "    (transformer): XLNetModel(\n",
       "      (word_embedding): Embedding(32000, 768)\n",
       "      (layer): ModuleList(\n",
       "        (0): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (4): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (5): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (6): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (7): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (8): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (9): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (10): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (11): XLNetLayer(\n",
       "          (rel_attn): XLNetRelativeAttention(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ff): XLNetFeedForward(\n",
       "            (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (activation_function): GELUActivation()\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (sequence_summary): SequenceSummary(\n",
       "      (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "      (first_dropout): Identity()\n",
       "      (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (logits_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('e_44_100.ckpt', map_location=device))\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e79cc29-b2e9-4c01-b7bc-6daa83bb8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dataloader(songs):\n",
    "    tokenized_texts = [tokenizer.tokenize(song) for song in songs]\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    attention_masks = []\n",
    "\n",
    "\n",
    "    for seq in input_ids:\n",
    "        seq_mask = [float(i>0) for i in seq]\n",
    "        attention_masks.append(seq_mask)\n",
    "    validation_inputs = torch.tensor(input_ids)\n",
    "    validation_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    validation_data = TensorDataset(validation_inputs, validation_masks)\n",
    "    validation_sampler = SequentialSampler(validation_data)\n",
    "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "    \n",
    "    return validation_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "557f9061-8f9d-4f0a-8d0e-9a6130612ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:13: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "<>:13: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "/tmp/ipykernel_54453/796845387.py:13: SyntaxWarning: 'str' object is not callable; perhaps you missed a comma?\n",
      "  print(\"Step: %s\" (step/len(validation_dataloader)))\n"
     ]
    }
   ],
   "source": [
    "def eval(validation_dataloader):\n",
    "    model.eval()\n",
    "    val_len = 0\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(validation_dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_input_mask = batch\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            preds = outputs[0].detach().cpu().numpy()\n",
    "            if step%100 == 0 and step:\n",
    "                print(\"Step: %s\" (step/len(validation_dataloader)))\n",
    "\n",
    "            predictions.append(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fba1b7cd-ec7c-451f-8464-3d1e55a9f8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(lyr):\n",
    "    lyricstring = \"\"\n",
    "    for line in lyr:\n",
    "        if line != '':\n",
    "            lyricstring = lyricstring + line + \" \"\n",
    "    cleanr = re.compile('\\[.*?\\]|\\(.*?\\)')\n",
    "    lyricstring = re.sub(cleanr, '', lyricstring.lower()) \n",
    "    punct = \"\"\n",
    "    for p in string.punctuation:\n",
    "        if p != '`' and p != \"'\":\n",
    "            punct = punct + p\n",
    "    lyricstring = \"\".join([char for char in lyricstring if char not in punct])\n",
    "    \n",
    "    return lyricstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "903c5476-813a-4315-94a2-d737ec926367",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"track-lyrics.json\") as f:\n",
    "    track_lyrics = json.load(f)\n",
    "track_lyrics = list(map(lambda x: x.split(\"\\n\")[1:], track_lyrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d057420-c2fc-4027-b8a4-06a3d5fcf290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 3652/3652 [00:02<00:00, 1776.74it/s]\n"
     ]
    }
   ],
   "source": [
    "list_lyrics = []\n",
    "for i in range(len(track_lyrics)):\n",
    "    list_lyrics.append(clean(track_lyrics[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb5c7355-8510-4714-a006-48f5e5635587",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = Dataloader(list_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab483ea-9db1-4f52-b79f-8dee748f24e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = eval(vd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b936560e-84fd-4019-b635-814832cbe421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.55828905, -1.794007  ,  1.5331506 ,  0.834533  ],\n",
      "       [-1.413558  , -0.02864932,  2.1458972 , -0.5030216 ],\n",
      "       [-0.8137109 , -0.39609116,  2.4109771 , -0.72511405],\n",
      "       [ 0.26034573, -0.8777653 ,  1.0417238 ,  0.35517716],\n",
      "       [-1.344079  , -0.86249316,  4.7164974 , -1.7720084 ],\n",
      "       [ 1.3024284 , -1.6338828 ,  0.3404919 ,  1.4989481 ],\n",
      "       [ 0.20670183, -0.1348671 ,  0.45600075,  0.0731061 ],\n",
      "       [ 0.83906615, -1.3575709 , -0.116785  ,  1.684588  ]],\n",
      "      dtype=float32), array([[ 1.5307236 , -1.9505694 , -0.68550193,  2.5091457 ],\n",
      "       [ 0.894444  , -1.7056776 , -0.19522905,  2.3239458 ]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "587977e1-91b0-4c65-957a-e00f46f35a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
